% 
% COG403 - Bias and Context - Report
% Sample LaTeX Paper -- Proceedings Format
% 



%% Change "letterpaper" in the following line to "a4paper" if you must.

\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}

\cogscifinalcopy % Uncomment this line for the final submission 


\usepackage{pslatex}
\usepackage{apacite}
\usepackage{float} % Roger Levy added this and changed figure/table
                   % placement to [H] for conformity to Word template,
                   % though floating tables and figures to top is
                   % still generally recommended!

%\usepackage[none]{hyphenat} % Sometimes it can be useful to turn off
%hyphenation for purposes such as spell checking of the resulting
%PDF.  Uncomment this block to turn off hyphenation.


%\setlength\titlebox{4.5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 4.5cm (the original size).
%%If you do, we reserve the right to require you to change it back in
%%the camera-ready version, which could interfere with the timely
%%appearance of your paper in the Proceedings.



\title{Bias and Context: Using Word Embeddings to Compare Word Use Across Contexts}
 
\author{{\large \bf Eric Schnell} \\
  
  \AND {\large \bf Ariyo Vahdat} \\}


\begin{document}

\maketitle


\begin{abstract}
Include no author information in the initial submission, to facilitate
blind review.  The abstract should be one paragraph, indented 1/8~inch on both sides,
in 9~point font with single spacing. The heading ``{\bf Abstract}''
should be 10~point, bold, centered, with one line of space below
it. This one-paragraph abstract section is required only for standard
six page proceedings papers. Following the abstract should be a blank
line, followed by the header ``{\bf Keywords:}'' and a list of
descriptive keywords separated by semicolons, all in 9~point font, as
shown below.

\textbf{Keywords:} 
add your choice of indexing terms or keywords; kindly use a
semicolon; between each term
\end{abstract}

\section{Methods}

\subsection{Word Embeddings}

The study utilized 250-dimensional word embeddings, trained using the word2vec algorithm operationalized by the gensim package for Python 3. They were trained using gensim’s default parameters. Notably the window size for training was 5, each word needed to be more than one letter long, and each word needed to appear at least 5 times to be included in the model. We trained six word embedding models using datasets of various contexts and discussing various topics.

\subsection{Datasets}

In this study we used six datasets, four of which came from Reddit, one from CNN, and one from the Daily Mail. These datasets represent different contexts and topics which vary in terms of their formality. For a casual context we used Reddit, a social media site where anyone can post topics of discussion and have people comment their replies. The Reddit datasets we used is made up of comments rather than posts, as comments are more discussion oriented, whereas posts are often short descriptions or stories. The news datasets, which represented a formal context, are CNN and the Daily Mail.

We have also separated our datasets based on formality of topic being discussed. Two of our Reddit datasets pulled comments from the entire site, and thus mostly comprised of casual topics. Two of our Reddit datasets only used comments on posts concerning news and politics, thus being discussion on more formal or serious topics. Specifically, these formal topics were from comments on posts found in the communities r/politics, which focuses on American politics, r/news, which focuses on American news, and r/worldnews, which focuses on news from around the world. For the news datasets, the CNN was considered to be discussing formal topics and the Daily Mail was considered to be discussing casual topics. The reason for this is that CNN typically focuses more on traditional news and politics, whereas the Daily Mail is a tabloid and focuses a lot on celebrity news and gossip. It must be noted that in all these cases the lines between casual and formal are not so clear as presented here. For instance, CNN will also discuss celebrities and the Daily Mail will also discuss politics, but the more common topics will be the ones with a larger influence on the word embeddings and so for the sake of the paper these categories will be used.
	
The datasets used for the news sites comes from Hermann et al. for their 2015 paper “Teaching Machines to Read and Comprehend”. They gathered CNN articles from 2007 until 2015 and Daily Mail articles from 2010 until 2015. The researchers posted their program for the set of articles. These datasets were then hosted online by Kyunghyun Cho at New York University,\footnote{https://cs.nyu.edu/~kcho/DMQA/} which is the dataset used in this study. For the Reddit data, we used a dataset made and hosted by pushshift.io.\footnote{https://files.pushshift.io/reddit/comments/} This group gathers all reddit posts and comments, with metadata as provided by Reddit, for a given month and then hosts that file on their website. The months used in this study are from September 2019 and January 2014. The reason for having two months is that we wanted the most recent data available (2019) and a dataset from the same time frame as the news datasets (2014). We do not expect there to be a significant difference between the separate reddit datasets.
	
To ensure that each word embedding model was relatively equal in their representation, each model was made from a corpus of 35 million words. This is considered small for a corpus for building a word2vec model, however we were limited by the file limit size on github which was used for sharing data among researchers. Furthermore, the news Reddit data from January 2014 only included 34 422 118 words, so a limit of 35 million words could also ensure all the corpuses were roughly even in size. To ensure that the Reddit data was comprised of comments which was in fact discussion, we removed any comment shorter than 10 words. For data cleanup purposes the first line of each news article was omitted as it included text that was not part of the article and it did not always follow the same format. Table 1 lays out the final relevant statistics for each dataset, where “All xxxx” represents the dataset of all reddit comments from the relevant year and “News xxxx” represents the dataset of reddit comments pertaining to news and politics of the relevant year.

\begin{table}[H]
\begin{center} 
\caption{Dataset Statistics.} 
\label{dataset-stat} 
\vskip 0.12in
\begin{tabular}{llll} 
\hline
Dataset    & \# of    & \# of Total & \# of Unique \\
           &  Entries & Words       & Words        \\
\hline
All 2019   & 820 587  & 35 000 247  & 81 008       \\
All 2014   & 845 925  & 35 000 004  & 72 218       \\
News 2019  & 760 393  & 35 000 039  & 49 897       \\
News 2014  & 664 873  & 34 422 118  & 52 258       \\
CNN        & 54 403   & 35 000 478  & 75 810       \\
Daily Mail & 58 031   & 35 000 381  & 79 159       \\
\hline
\end{tabular} 
\end{center} 
\end{table}

\subsection{Analysis}

TYPE HERE

\section{Results}

\section{Discussion}

First, we will examine the role of context on bias in our results. The results show a significant bias in all datasets for the career versus family gender bias test. Furthermore, all reddit comments of 2014 and 2019, as well news reddit comments of 2014, CNN and the Daily Mail all show a very significant effect with p < 0.005. A significant gender bias is only found for one other test and it is found in one casual context dataset and one formal context dataset. For WEAT values, gender bias appears to be more prevalent in the formal context. However, with regards to the p value, it appears that context plays no significant effect on gender bias, as when a significant bias is present, the p value of casual and formal contexts are quite similar. With respect to racial bias, this bias only arises in the formal context. Overall it appears that bias is more prevalent in a formal context rather than a casual one, which is the opposite of our predicted hypothesis.

It must also be noted that there is a conflicting effect of formality of topic on bias. In the case of gender bias, where there was significant bias, the casual topic Reddit data had more bias than the formal topic Reddit data. Whereas the formal topic news data had more bias in the career versus family test, but less bias in the math versus arts test. With respect to racial bias the formal news topic had more bias than the casual news topic. So, there are conflicting effects of topic formality on bias and thus this topic formality does not appear to play a role in bias.

To understand why the results go against our hypothesis, we must look at the most significant issue with our word embeddings, that being the size of the corpus with which we trained our word embeddings. According to \citeA{Lai2016a}, when working with corpuses which focus on a specific domain, the larger the corpus the better. Notably they found that corpuses built from over 1 billion words performed much better than ones of 100 million words. In our case we had a significantly smaller corpus of just roughly 35 million words each. Another issue may have been the dimensionality of our corpus. In the relevant literature concerning bias in word embeddings, word embeddings are typically either 200 \cite{Kozlowski2019a} or 300 \cite{Caliskan2017a} dimensional vectors. Our thinking was to split the difference and use 250-dimensional vectors. However, these papers used much larger corpuses to build their embeddings, and thus a higher dimensionality was required. It could be that the dimensionality we used was too large given our corpus size, and that we should have rather made 200-dimensional or even 100-dimensional word embeddings. However, the clearer issue is that of our corpus size.

This issue of corpus size not only suggests that our results are not representative of true bias, but it may also suggest why we found more bias in the formal context. News sites follow major stories over large periods of time and write many articles about the same story. They also cover many similar stories and each story is considerably longer than the average reddit comment. As such the corpus is much more focused for news sites than for Reddit, which in turn means that the word embedding will more accurately reflect trends in the data and can more easily pick up on any bias in the data. Seeing as Reddit will have a more varied focus, especially when taking comments from all subreddits, it is more difficult for our word embeddings to accurately characterize the corpus. This issue becomes even more severe considering the small corpus sizes used. Comparatively the focused corpus of news sites leads to more accurate word embeddings which make bias more noticeable.

Another possibility is that Reddit is simply less biased than news sites. The lack of barrier to entry on Reddit may make it more diverse and representative of varied viewpoints. It could mean that there is less bias overall as biased individuals are countered by ones who hold opposite viewpoints. On the other hand, articles on the Daily Mail and CNN are all written by journalists. Seeing as these organisations do not release such details about their journalists, it is impossible to know for sure the backgrounds and educations of all the journalists, but it can be safely assumed that they are mostly college-educated. This means they are bringing specific backgrounds, not shared by all, into their writing. As such journalists may reinforce biases innate to the craft that may not be found on a more open platform such as Reddit. In this sense then we are not comparing whether people are more likely to use biased language in a casual rather than a formal context, but rather we are comparing the bias amongst two specific populations. Rather we would want to compare bias across context for the same group of speakers. Reddit may simply be less biased than the news, but this does not answer whether bias is stronger in a casual or formal context.

On top of the issues with corpus size, the corpus selection could also have impacted the results. Seeing as we built word embeddings for each separate corpus, there may have been other factors built into these corpuses that impact bias but have nothing to do with context. The most obvious of these is political alignment. Three of our four types of datasets discuss politics and the news and so the political alignment found in each of these datasets will be significant in how it is discussed. CNN and the popular political subreddits are considered left-leaning, whereas the Daily Mail is considered right-leaning. These political leanings could have impacted the bias of the corpus while circumnavigating the context of the discussion.

The tests used may have swayed our results. It seems clear that our models do have some level of bias which can be found, seeing as for one test this bias was overwhelming. However, it may be that the other tests were incorrectly chosen to truly study bias. We selected attribute words and target words as found in \citeA{Caliskan2017a} and \citeA{Garg2018a}, and so we had assumed that this meant that these were reliable tests. Of our tests, only the career versus family gender bias test had results similar to that found in the original paper. For this test, \citeA{Caliskan2017a} had a distance score of 1.89, which is similar to some of the results we had, notably for the Daily Mail and CNN datasets at 1.96 and 1.82 respectively. In our other gender bias tests that found a significant bias, the scores were quite distant from that in \citeA{Caliskan2017a}. As for racial bias, the paper by \citeA{Garg2018a} from which we took our attribute words did not use the WEAT test so we cannot directly compare our results to theirs. The question now becomes, how come we got such similar results to one test, but for none others? It could be that we overestimated the accuracy of the original tests and instead we should have taken tests from more papers as well as creating our own tests. It could also be an issue of corpus size. The career versus family test had the largest WEAT score by a considerable margin in \citeA{Caliskan2017a}. This bias towards women with regards to career versus family is also well documented in other word embedding literature \cite{Bolukbasi2016a}. As such it would appear to be the easiest bias for our model to uncover. So, with models built from small corpuses, this is the test that is most likely to return a significant bias. Seeing as we know at least one WEAT test can successfully uncover bias, it could be that with models built from larger corpuses the other tests would have also uncovered a significant bias. Regardless, the tests that we chose could have impacted the sort of results we found.

\section{Conclusion}

We failed to prove our hypothesis that a more casual context would promote more bias in conversation. In fact, we found there to be very little bias in our various corpuses and when bias was uncovered it appeared stronger in the formal context than in the casual context. We attempted to prove this using word embeddings, specifically word2vec, and we suspect that our results were negatively impacted by the fact that these embeddings were trained on very small corpuses. We still believe that our hypothesis is plausible, however in the future it would need to be tested on larger corpuses of text. It would also be good to draw our corpuses from more varied sources and to use more test cases. If the hypothesis were to be proven, an interesting next study could be to compare bias in spoken versus written text, again using word embeddings where the word embeddings for spoken texts would be built on their transcription. This would look at whether the fact that written text can be deliberated on longer means that bias would be more likely to be eliminated. However, before moving onto this project it is important to further study the role of context in bias. Although the results found do not align with the hypothesis, we are still hopeful that by using larger corpuses we could eliminate many of the faults of the current study and in fact prove the hypothesis.

\section{General Formatting Instructions}

The entire content of a paper (including figures, references, and anything else) can be no longer than six pages in the \textbf{initial submission}. In the \textbf{final submission}, the text of the paper, including an author line, must fit on six pages. Up to one additional page can be used for acknowledgements and references.

The text of the paper should be formatted in two columns with an
overall width of 7 inches (17.8 cm) and length of 9.25 inches (23.5
cm), with 0.25 inches between the columns. Leave two line spaces
between the last author listed and the text of the paper; the text of
the paper (starting with the abstract) should begin no less than 2.75 inches below the top of the
page. The left margin should be 0.75 inches and the top margin should
be 1 inch.  \textbf{The right and bottom margins will depend on
  whether you use U.S. letter or A4 paper, so you must be sure to
  measure the width of the printed text.} Use 10~point Times Roman
with 12~point vertical spacing, unless otherwise specified.

The title should be in 14~point bold font, centered. The title should
be formatted with initial caps (the first letter of content words
capitalized and the rest lower case). In the initial submission, the
phrase ``Anonymous CogSci submission'' should appear below the title,
centered, in 11~point bold font.  In the final submission, each
author's name should appear on a separate line, 11~point bold, and
centered, with the author's email address in parentheses. Under each
author's name list the author's affiliation and postal address in
ordinary 10~point type.

Indent the first line of each paragraph by 1/8~inch (except for the
first paragraph of a new section). Do not add extra vertical space
between paragraphs.


\section{First Level Headings}

First level headings should be in 12~point, initial caps, bold and
centered. Leave one line space above the heading and 1/4~line space
below the heading.


\subsection{Second Level Headings}

Second level headings should be 11~point, initial caps, bold, and
flush left. Leave one line space above the heading and 1/4~line
space below the heading.


\subsubsection{Third Level Headings}

Third level headings should be 10~point, initial caps, bold, and flush
left. Leave one line space above the heading, but no space after the
heading.


\section{Formalities, Footnotes, and Floats}

Use standard APA citation format. Citations within the text should
include the author's last name and year. If the authors' names are
included in the sentence, place only the year in parentheses, as in
\citeA{NewellSimon1972a}, but otherwise place the entire reference in
parentheses with the authors and year separated by a comma
\cite{NewellSimon1972a}. List multiple references alphabetically and
separate them by semicolons
\cite{ChalnickBillman1988a,NewellSimon1972a}. Use the
``et~al.'' construction only after listing all the authors to a
publication in an earlier reference and for citations with four or
more authors.


\subsection{Footnotes}

Indicate footnotes with a number\footnote{Sample of the first
footnote.} in the text. Place the footnotes in 9~point font at the
bottom of the column on which they appear. Precede the footnote block
with a horizontal rule.\footnote{Sample of the second footnote.}


\subsection{Tables}

Number tables consecutively. Place the table number and title (in
10~point) above the table with one line space above the caption and
one line space below it, as in Table~\ref{sample-table}. You may float
tables to the top or bottom of a column, and you may set wide tables across
both columns.

\begin{table}[H]
\begin{center} 
\caption{Sample table title.} 
\label{sample-table} 
\vskip 0.12in
\begin{tabular}{ll} 
\hline
Error type    &  Example \\
\hline
Take smaller        &   63 - 44 = 21 \\
Always borrow~~~~   &   96 - 42 = 34 \\
0 - N = N           &   70 - 47 = 37 \\
0 - N = 0           &   70 - 47 = 30 \\
\hline
\end{tabular} 
\end{center} 
\end{table}


\subsection{Figures}

All artwork must be very dark for purposes of reproduction and should
not be hand drawn. Number figures sequentially, placing the figure
number and caption, in 10~point, after the figure with one line space
above the caption and one line space below it, as in
Figure~\ref{sample-figure}. If necessary, leave extra white space at
the bottom of the page to avoid splitting the figure and figure
caption. You may float figures to the top or bottom of a column, and
you may set wide figures across both columns.

\begin{figure}[H]
\begin{center}
\fbox{CoGNiTiVe ScIeNcE}
\end{center}
\caption{This is a figure.} 
\label{sample-figure}
\end{figure}


\section{Acknowledgments}

In the \textbf{initial submission}, please \textbf{do not include
  acknowledgements}, to preserve anonymity.  In the \textbf{final submission},
place acknowledgments (including funding information) in a section \textbf{at
the end of the paper}.


\section{References Instructions}

Follow the APA Publication Manual for citation format, both within the
text and in the reference list, with the following exceptions: (a) do
not cite the page numbers of any book, including chapters in edited
volumes; (b) use the same format for unpublished references as for
published ones. Alphabetize references by the surnames of the authors,
with single author entries preceding multiple author entries. Order
references by the same authors by the year of publication, with the
earliest first.

Use a first level section heading, ``{\bf References}'', as shown
below. Use a hanging indent style, with the first line of the
reference flush against the left margin and subsequent lines indented
by 1/8~inch. Below are example references for a conference paper, book
chapter, journal article, dissertation, book, technical report, and
edited volume, respectively.

\nocite{Garg2018a}
\nocite{Caliskan2017a}
\nocite{Lai2016a}
\nocite{Kozlowski2019a}
\nocite{Bolukbasi2016a}

\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{CogSci_Template}


\end{document}